{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWogzWb0QHzv"
      },
      "outputs": [],
      "source": [
        "# Skin Cancer Detection\n",
        "\n",
        "### Import required libraries\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import textwrap as tw\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn import svm\n",
        "\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.applications.resnet import preprocess_input\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "### EDA\n",
        "\n",
        "data = pd.read_csv(\"./ISIC_2019_Training_GroundTruth.csv\", header = 0)\n",
        "data.head(20)\n",
        "\n",
        "data.info()\n",
        "\n",
        "data.tail()\n",
        "\n",
        "data.describe()\n",
        "\n",
        "data.corr()\n",
        "\n",
        "lesion_type_dict = {\n",
        "    'NV': 'Melanocytic nevi',\n",
        "    'MEL': 'Melanoma',\n",
        "    'BKL': 'Benign keratosis ',\n",
        "    'BCC': 'Basal cell carcinoma',\n",
        "    'AK': 'Actinic keratoses',\n",
        "    'VASC': 'Vascular lesions',\n",
        "    'DF': 'Dermatofibroma',\n",
        "    'SCC' : 'Squamous cell carcinoma'\n",
        "}\n",
        "\n",
        "# print all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# inhibit graphics card runs out of memory\n",
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)### Step 1: Load and preprocess the image within the CNN architecture\n",
        "\n",
        "### Step 1: Load and preprocess the image within the CNN architecture\n",
        "\n",
        "def load_data(path: str):\n",
        "    dir = Path(path)\n",
        "\n",
        "    # list of all filepathes\n",
        "    filepaths = list(dir.glob(r'**/*.jpg'))\n",
        "\n",
        "    # list of labels extracted from last foldername of filepath\n",
        "    labels = list(map(lambda l: os.path.split(os.path.split(l)[0])[1], filepaths))\n",
        "\n",
        "    # series of string filepathes\n",
        "    filepaths = pd.Series(filepaths, name='FilePaths').astype(str)\n",
        "\n",
        "    # series of string labels\n",
        "    labels = pd.Series(labels, name='Labels').astype(str)\n",
        "\n",
        "    # merge series to dataframe df\n",
        "    df = pd.merge(filepaths, labels, right_index=True, left_index=True)\n",
        "\n",
        "    # Resampling complete rows and reset the index\n",
        "    return df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df = load_data('./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train')\n",
        "\n",
        "# total categires\n",
        "len(os.listdir('./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train'))\n",
        "\n",
        "os.listdir('./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train')\n",
        "\n",
        "list_diseases = os.listdir('./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train')\n",
        "\n",
        "results2 = []\n",
        "for disease in list_diseases:\n",
        "    dies_name_count = {}\n",
        "    count_disease = len(os.listdir(f'./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train'))\n",
        "    dies_name_count['disease'] = disease\n",
        "    dies_name_count['count_images'] = count_disease\n",
        "    results2.append(dies_name_count)\n",
        "\n",
        "results = pd.DataFrame(results2)\n",
        "results\n",
        "\n",
        "df.head(15)\n",
        "\n",
        "df.info()\n",
        "\n",
        "# ordered count of rows per unique label\n",
        "labels_count = df['Labels'].value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(labels_count.index,labels_count.values)\n",
        "sns.despine()\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)\n",
        "\n",
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(row['Labels'] == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df['Labels'].unique())\n",
        "# loop through labels\n",
        "for label in labels:\n",
        "    plot_images_per_label(df, label, 3, (12,9))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# stratified train and val (25%) datasets\n",
        "X_train, X_val = train_test_split(df, test_size=0.25, stratify=df['Labels'], random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Val Data: ', X_val.shape)\n",
        "\n",
        "# number of samples/images per iteration\n",
        "BATCH_SIZE = 32\n",
        "# input image size\n",
        "IMG_SIZE = (224, 224)\n",
        "# count of epchos\n",
        "EPOCHS = 10\n",
        "\n",
        "# image preprocessing\n",
        "img_data_gen = ImageDataGenerator(shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  preprocessing_function=preprocess_input)\n",
        "\n",
        "X_train = img_data_gen.flow_from_dataframe(dataframe=X_train,\n",
        "                                           x_col='FilePaths',\n",
        "                                           y_col='Labels',\n",
        "                                           target_size=IMG_SIZE,\n",
        "                                           color_mode='rgb',\n",
        "                                           class_mode='categorical',\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           seed=1)\n",
        "\n",
        "X_val = img_data_gen.flow_from_dataframe(dataframe=X_val,\n",
        "                                         x_col='FilePaths',\n",
        "                                         y_col='Labels',\n",
        "                                         target_size=IMG_SIZE,\n",
        "                                         color_mode='rgb',\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size=BATCH_SIZE,\n",
        "                                         seed=1)\n",
        "\n",
        "fit, ax = plt.subplots(nrows=3, ncols=3, figsize=(12,15))\n",
        "\n",
        "for i, a in enumerate(ax.flat):\n",
        "    img, label = X_train.next()\n",
        "    a.imshow(img[0],)\n",
        "    a.set_title(label[0])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#training data\n",
        "training_dir=\"./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\n",
        "\n",
        "#increases amount of data by making different forms of image\n",
        "training_generator = ImageDataGenerator(rescale=1/255,\n",
        "                                        featurewise_center = True,\n",
        "                                        samplewise_center=True,\n",
        "                                        featurewise_std_normalization=False,\n",
        "                                        samplewise_std_normalization=True,\n",
        "                                        zca_whitening=False,\n",
        "                                        rotation_range=30,\n",
        "                                        zoom_range=0.2,\n",
        "                                        width_shift_range=0.1,\n",
        "                                        height_shift_range=0.1,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=True)\n",
        "\n",
        "#creates accessible training data\n",
        "train_generator=training_generator.flow_from_directory(training_dir,target_size=(224,224),\n",
        "                                                       batch_size=4,class_mode='binary')\n",
        "\n",
        "#validation data\n",
        "validation_dir=\"./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test\"\n",
        "\n",
        "#increases amount of data by making different forms of image\n",
        "validation_generator=ImageDataGenerator(rescale=1/255)\n",
        "val_generator=validation_generator.flow_from_directory(validation_dir,target_size=(224,224), batch_size=4, class_mode='binary')\n",
        "\n",
        "#testing data\n",
        "testing_dir=\"./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test\"\n",
        "\n",
        "#increases amount of data by making different forms of image\n",
        "testing_generator = ImageDataGenerator(rescale=1/255,\n",
        "                                        featurewise_center = False,\n",
        "                                        samplewise_center=False,\n",
        "                                        featurewise_std_normalization=False,\n",
        "                                        samplewise_std_normalization=False,\n",
        "                                        zca_whitening=False,\n",
        "                                        rotation_range=30,\n",
        "                                        zoom_range=0.2,\n",
        "                                        width_shift_range=0.1,\n",
        "                                        height_shift_range=0.1,\n",
        "                                        horizontal_flip=False,\n",
        "                                        vertical_flip=False)\n",
        "\n",
        "#creates accessible testing data\n",
        "test_generator=training_generator.flow_from_directory(testing_dir,target_size=(224,224),\n",
        "                                                       batch_size=4,class_mode='binary')\n",
        "\n",
        "#model sequelling\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), input_shape = (224,224,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#compiling the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# stop training when accuracy has stopped improving\n",
        "cb = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3)\n",
        "hst = model.fit(X_train, validation_data=X_val, epochs=EPOCHS, callbacks=cb)\n",
        "\n",
        "# train model\n",
        "hst = model.fit(X_train, validation_data=X_val, epochs=EPOCHS)\n",
        "\n",
        "acc = hst.history['acc']\n",
        "val_acc = hst.history['val_acc']\n",
        "loss = hst.history['loss']\n",
        "val_loss = hst.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs,acc,'r', label = 'Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc= 0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "X_test = load_data('./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test')\n",
        "\n",
        "X_test.head(15)\n",
        "\n",
        "print('Test Data: ', X_test.shape)\n",
        "\n",
        "# ordered count of rows per unique label\n",
        "X_test['Labels'].value_counts(ascending=True)\n",
        "\n",
        "#### Image Preprocessing\n",
        "\n",
        "X_test = img_data_gen.flow_from_dataframe(dataframe=X_test,\n",
        "                                          x_col='FilePaths',\n",
        "                                          y_col='Labels',\n",
        "                                          target_size=IMG_SIZE,\n",
        "                                          color_mode='rgb',\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False, # necessary fpr confusion matrix\n",
        "                                          seed=1)\n",
        "\n",
        "res = model.evaluate(X_test)\n",
        "\n",
        "#### Accuracy and loss\n",
        "\n",
        "print(f'Train Accuracy: {hst.history[\"acc\"][-1:][0] * 100:.2f}')\n",
        "print(f'Val Accuracy: {hst.history[\"val_acc\"][-1:][0] * 100:.2f}')\n",
        "print(f'Test Accuracy: {res[1] * 100:.2f}')\n",
        "\n",
        "print(f'Train Loss: {hst.history[\"loss\"][-1:][0] * 100:.2f}')\n",
        "print(f'Val Loss: {hst.history[\"val_loss\"][-1:][0] * 100:.2f}')\n",
        "print(f'Test Loss: {res[0] * 100:.2f}')\n",
        "\n",
        "#### Predicted Labels and Rounded Labels\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "print(\"Y_pred\", Y_pred.shape)\n",
        "\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print(\"y_pred\", y_pred.size)\n",
        "\n",
        "#### True Labels and Label Classes\n",
        "\n",
        "y_true = X_test.classes\n",
        "print(\"y_pred\", len(y_pred))\n",
        "\n",
        "class_labels = list(X_test.class_indices.keys())\n",
        "print(\"labels\", len(class_labels))\n",
        "\n",
        "# compare with true labels\n",
        "cfm = confusion_matrix(y_pred, y_true, normalize='true')\n",
        "\n",
        "# plot size\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "\n",
        "# print confusion matrix\n",
        "s = sns.heatmap(cfm,\n",
        "               annot=True,\n",
        "               cmap=['#ff0001', '#09AA11'],\n",
        "               center=0.8,\n",
        "               fmt='.1%',\n",
        "               linewidths=.5,\n",
        "               cbar_kws={'format': FuncFormatter(lambda x, pos: '{:.0%}'.format(x))},\n",
        "               linecolor='Black',\n",
        "               ax=ax)\n",
        "\n",
        "# set labels\n",
        "s.set(xlabel='Predict', ylabel='True')\n",
        "s.set(title='Confusion Matrix')\n",
        "s.set_yticklabels([tw.fill(e, 10) for e in class_labels])\n",
        "s.set_xticklabels([tw.fill(e, 10) for e in class_labels])\n",
        "\n",
        "def load_data(path: str):\n",
        "    dir = Path(path)\n",
        "\n",
        "    # list of all filepathes\n",
        "    filepaths = list(dir.glob(r'**/*.jpg'))\n",
        "\n",
        "    # list of labels extracted from last foldername of filepath\n",
        "    labels = list(map(lambda l: os.path.split(os.path.split(l)[0])[1], filepaths))\n",
        "\n",
        "    # series of string filepathes\n",
        "    filepaths = pd.Series(filepaths, name='FilePaths').astype(str)\n",
        "\n",
        "    # series of string labels\n",
        "    labels = pd.Series(labels, name='Labels').astype(str)\n",
        "\n",
        "    # merge series to dataframe df\n",
        "    df = pd.merge(filepaths, labels, right_index=True, left_index=True)\n",
        "\n",
        "    # Resampling complete rows and reset the index\n",
        "    return df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df = load_data('./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train')\n",
        "\n",
        "# Read Sample Image\n",
        "image_path = \"./input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test/basal cell carcinoma/ISIC_0024331.jpg\"\n",
        "image = plt.imread(image_path)\n",
        "\n",
        "plt.title(\"Sample Image\")\n",
        "plt.imshow(image)\n",
        "\n",
        "preprocessed_image = model.output\n",
        "preprocessed_image = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "### Step 1: Preprocessing\n",
        "\n",
        "#### Step 1.1: Apply Hough's transform to remove hair\n",
        "\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "# Apply Hough's transform to detect lines representing hair\n",
        "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=100, maxLineGap=10)\n",
        "\n",
        "# Create a mask image to draw the detected lines\n",
        "mask = np.zeros_like(image)\n",
        "\n",
        "# Draw the detected lines on the mask image\n",
        "for line in lines:\n",
        "    x1, y1, x2, y2 = line[0]\n",
        "    cv2.line(mask, (x1, y1), (x2, y2), (255, 255, 255), thickness=2)\n",
        "\n",
        "# Apply bitwise AND operation to remove hair from the original image\n",
        "hair_removed = cv2.bitwise_and(image, cv2.bitwise_not(mask))\n",
        "\n",
        "plt.title(\"Hair Removal\")\n",
        "plt.imshow(hair_removed)\n",
        "\n",
        "#### Step 1.2: Apply MATLAB filters to remove shade and glare\n",
        "\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply shading correction filter (e.g., morphological opening)\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "shading_corrected = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n",
        "\n",
        "# Apply glare removal filter (e.g., guided filter)\n",
        "radius = 10\n",
        "epsilon = 0.1\n",
        "glare_removed = cv2.ximgproc.guidedFilter(shading_corrected, gray, radius, epsilon)\n",
        "\n",
        "# Convert the image back to color if needed\n",
        "if len(image.shape) == 3:\n",
        "    glare_removed = cv2.cvtColor(glare_removed, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "plt.title(\"Glare Removal\")\n",
        "plt.imshow(glare_removed)\n",
        "\n",
        "#### Step 1.3: Perform contrast enhancement\n",
        "\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply contrast enhancement algorithm (e.g., histogram equalization)\n",
        "enhanced = cv2.equalizeHist(gray)\n",
        "\n",
        "# Convert the enhanced grayscale image back to the original color space if needed\n",
        "if len(image.shape) == 3:\n",
        "    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "plt.title(\"Contrast Enhancement\")\n",
        "plt.imshow(enhanced)\n",
        "\n",
        "### Step 2: Perform segmentation using Otsu's thresholding\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = rgb2gray(image)\n",
        "\n",
        "plt.title(\"Grayscaled Image\")\n",
        "plt.imshow(gray_image)\n",
        "\n",
        "# Apply histogram equalization\n",
        "equalized_image = cv2.equalizeHist((gray_image * 255).astype(np.uint8))\n",
        "\n",
        "plt.title(\"Histogram Equalization\")\n",
        "plt.imshow(equalized_image)\n",
        "\n",
        "# Perform Otsu's thresholding\n",
        "threshold_value = threshold_otsu(equalized_image)\n",
        "binary_image = (equalized_image > threshold_value).astype(np.uint8)\n",
        "\n",
        "plt.title(\"Binarized Image\")\n",
        "plt.imshow(binary_image)\n",
        "\n",
        "### Step 3: Extract features\n",
        "\n",
        "# Compute the area of the segmented region\n",
        "area = np.sum(binary_image)\n",
        "\n",
        "# Compute the mean, variance, and standard deviation of the segmented region\n",
        "masked_image = gray_image * binary_image\n",
        "mean = np.mean(masked_image)\n",
        "variance = np.var(masked_image)\n",
        "std_dev = np.std(masked_image)\n",
        "\n",
        "features = [mean, variance, std_dev, area]\n",
        "\n",
        "features\n",
        "\n",
        "### Step 4: Process image to get mean value of red, blue, and green pixels\n",
        "\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Get the pixel data of the image\n",
        "pixels = image[0:image.shape[0], 0:image.shape[1], 0:4]\n",
        "\n",
        "# Initialize variables for accumulating the total sum of red, green, and blue values\n",
        "total_red = 0\n",
        "total_green = 0\n",
        "total_blue = 0\n",
        "\n",
        "# Iterate over each pixel in the image\n",
        "for y in range(image.shape[1]):\n",
        "    for x in range(image.shape[0]):\n",
        "        # Get the RGB values of the current pixel\n",
        "        r, g, b = pixels[x, y]\n",
        "\n",
        "        # Accumulate the RGB values\n",
        "        total_red += r\n",
        "        total_green += g\n",
        "        total_blue += b\n",
        "\n",
        "# Calculate the mean values\n",
        "num_pixels = image.shape[0] * image.shape[1]\n",
        "mean_red = total_red / num_pixels\n",
        "mean_green = total_green / num_pixels\n",
        "mean_blue = total_blue / num_pixels\n",
        "\n",
        "# Calculate the mean color distance threshold\n",
        "threshold = 90\n",
        "\n",
        "# Iterate over each pixel again to check and discard portions based on mean color distance\n",
        "for y in range(image.shape[1]):\n",
        "  for x in range(image.shape[0]):\n",
        "      # Get the RGB values of the current pixel\n",
        "      r, g, b = pixels[x, y]\n",
        "\n",
        "      # Calculate the Euclidean distance between the pixel's color and the mean color\n",
        "      distance = ((r - mean_red) ** 2 + (g - mean_green) ** 2 + (b - mean_blue) ** 2) ** 0.5\n",
        "\n",
        "      # Discard the pixel if the mean color distance is less than the threshold\n",
        "      if distance < threshold:\n",
        "          pixels[x, y] = (0, 0, 0)  # Set the pixel to black\n",
        "\n",
        "plt.title(\"RGB Thresholding\")\n",
        "plt.imshow(image)\n",
        "\n",
        "### Step 5: Perform border extraction to segment the image into lesion and background skin\n",
        "\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply edge detection (e.g., Canny edge detector)\n",
        "edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "# Apply threshold to obtain a binary image\n",
        "_, thresholded = cv2.threshold(edges, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Perform morphological operations (e.g., dilation) if needed\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "dilated = cv2.dilate(thresholded, kernel, iterations=1)\n",
        "\n",
        "# Create a segmented image by masking the original image with the extracted borders\n",
        "segmented = cv2.bitwise_and(image, image, mask=dilated)\n",
        "\n",
        "plt.title(\"Image Borders\")\n",
        "plt.imshow(segmented)\n",
        "\n",
        "### Step 6: Classify the image using Support Vector Machines (SVM)\n",
        "\n",
        "train,test = train_test_split(data, test_size = 100)\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "prediction_var = ['MEL', 'NV', 'BCC', 'AK', 'BKL','DF','VASC','SCC']\n",
        "\n",
        "train_X = train[prediction_var]\n",
        "train_Y = train.MEL\n",
        "test_X = test[prediction_var]\n",
        "test_Y = test.MEL\n",
        "\n",
        "model = svm.SVC()\n",
        "model.fit(train_X, train_Y)\n",
        "\n",
        "prediction = model.predict(test_X)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "from sklearn import metrics\n",
        "metrics.accuracy_score(prediction, test_Y)"
      ]
    }
  ]
}